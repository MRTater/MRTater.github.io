---  
title: "ViRED: Prediction of Visual Relations in Engineering Drawings"  
authors: [Chao Gu, Ke Lin, Yiyang Luo]  
venue: "Under Review"  
date: 2024-11-16  
tags: [2D Vision, Object Detection]  
teaser: /images/paper/ViRED.svg  
# link: ""  
# paperurl: "https://example.com/paper-url.pdf"  
# slidesurl: "https://example.com/slides-url.pdf"  
codeurl: "https://github.com/AInnovateLab/ViRED"  
projecturl: "https://ainnovatelab.github.io/ViRED/"  
abstract: "To accurately understand engineering drawings, it is essential to establish the correspondence between images and their description tables within the drawings. Existing document understanding methods predominantly focus on text as the main modality, which is not suitable for documents containing substantial image information. In the field of visual relation detection, the structure of the task inherently limits its capacity to assess relationships among all entity pairs in the drawings. To address this issue, we propose a vision-based relation detection model, named ViRED, to identify the associations between tables and circuits in electrical engineering drawings. Our model mainly consists of three parts: a vision encoder, an object encoder, and a relation decoder. We implement ViRED using PyTorch to evaluate its performance. To validate the efficacy of ViRED, we conduct a series of experiments. The experimental results indicate that, within the engineering drawing dataset, our approach attained an accuracy of 96% in the task of relation prediction, marking a substantial improvement over existing methodologies. The results also show that ViRED can inference at a fast speed even when there are numerous objects in a single engineering drawing."  
---  
